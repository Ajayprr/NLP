{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec-Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2zsgE0itT6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "corpus_raw = 'He is the king . The king is royal . She is the royal  queen '\n",
        "# convert to lower case\n",
        "corpus_raw = corpus_raw.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN_PpMGOuScS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "[Quick Brown Fox Example](https://drive.google.com/open?id=1n8ElxWjh1a9kdPTCBbCmvP7MKj5vtD4U)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOOLwDNJvMAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for word in corpus_raw.split():\n",
        "    if word != '.': # because we don't want to treat . as a word\n",
        "        words.append(word)\n",
        "words = set(words) # so that all duplicate words are removed\n",
        "word2int = {}\n",
        "int2word = {}\n",
        "vocab_size = len(words) # gives the total number of unique words\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "    int2word[i] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV31BodnvzmB",
        "colab_type": "code",
        "outputId": "11f4a6d9-abad-4d2a-e1fe-f45deb296ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(word2int['queen'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4XswQDrv2Q8",
        "colab_type": "code",
        "outputId": "7a1e0b94-b6ee-415e-b41f-70e6bd16bf46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(int2word[3])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "queen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-7dSt4Kv38y",
        "colab_type": "code",
        "outputId": "babddc6c-cd86-4358-c4e7-ef683c852e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(word2int['king'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRGOt530v8Pn",
        "colab_type": "code",
        "outputId": "f1534e7a-ae59-4763-8a79-7cb25addb46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(int2word[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_xKesDDG0bz",
        "colab_type": "text"
      },
      "source": [
        "### Creation of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuRxukAnv-Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw sentences is a list of sentences.\n",
        "raw_sentences = corpus_raw.split('.')\n",
        "sentences = []\n",
        "for sentence in raw_sentences:\n",
        "    sentences.append(sentence.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykFtbNPuwAsl",
        "colab_type": "code",
        "outputId": "1534a001-11b1-48fe-bb2c-028c715971c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sentences)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['he', 'is', 'the', 'king'], ['the', 'king', 'is', 'royal'], ['she', 'is', 'the', 'royal', 'queen']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAwveRYSG66C",
        "colab_type": "text"
      },
      "source": [
        "### Creation of windows for word pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ-Q73kewCgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "WINDOW_SIZE = 2\n",
        "for sentence in sentences:\n",
        "    for word_index, word in enumerate(sentence):\n",
        "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if nb_word != word:\n",
        "                data.append([word, nb_word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpAib9zvwGhv",
        "colab_type": "code",
        "outputId": "0fc2a268-aa14-4738-f346-f503ec257c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['he', 'is'], ['he', 'the'], ['is', 'he'], ['is', 'the'], ['is', 'king'], ['the', 'he'], ['the', 'is'], ['the', 'king'], ['king', 'is'], ['king', 'the'], ['the', 'king'], ['the', 'is'], ['king', 'the'], ['king', 'is'], ['king', 'royal'], ['is', 'the'], ['is', 'king'], ['is', 'royal'], ['royal', 'king'], ['royal', 'is'], ['she', 'is'], ['she', 'the'], ['is', 'she'], ['is', 'the'], ['is', 'royal'], ['the', 'she'], ['the', 'is'], ['the', 'royal'], ['the', 'queen'], ['royal', 'is'], ['royal', 'the'], ['royal', 'queen'], ['queen', 'the'], ['queen', 'royal']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwVhzptawNkQ",
        "colab_type": "text"
      },
      "source": [
        "### One-hot vector encoding\n",
        "say we have a vocabulary of 3 words : pen, pineapple, apple\n",
        "\n",
        "- word2int['pen'] -> 0 -> [1 0 0]\n",
        "- word2int['pineapple'] -> 1 -> [0 1 0]\n",
        "- word2int['apple'] -> 2 -> [0 0 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9h9GjwtwV9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to convert numbers to one hot vectors\n",
        "def to_one_hot(data_point_index, vocab_size):\n",
        "    temp = np.zeros(vocab_size)\n",
        "    temp[data_point_index] = 1\n",
        "    return temp\n",
        "x_train = [] # input word\n",
        "y_train = [] # output word\n",
        "for data_word in data:\n",
        "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
        "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n",
        "# convert them to numpy arrays\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eILuk7rlwZBf",
        "colab_type": "code",
        "outputId": "04c69dc3-2180-4717-b33a-9192845abde6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSQxWmzyFSjY",
        "colab_type": "code",
        "outputId": "a3706e19-3876-4368-be9a-d9672e5b84be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34, 7) (34, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQDUlqj6FX0f",
        "colab_type": "text"
      },
      "source": [
        "### Creation of Tensorflow model\n",
        "#### Create Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brDMNKnSFZ2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making placeholders for x_train and y_train\n",
        "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
        "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Jfu5juLRVq",
        "colab_type": "text"
      },
      "source": [
        "[Architecture](https://drive.google.com/open?id=1svyZ4AxL5YX4j1Wl_QGYVcCC9iiP6iXR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Non357FoCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 5 # you can choose your own number\n",
        "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
        "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM])) #bias\n",
        "hidden_representation = tf.add(tf.matmul(x,W1), b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqqxfksALbAL",
        "colab_type": "text"
      },
      "source": [
        "[Predictions](https://drive.google.com/open?id=122xvSIqD1G5tkAdO7BmT4gLAtKL990A4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiEaUAm4FwEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
        "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CmNWnahL-Sv",
        "colab_type": "text"
      },
      "source": [
        "[Summary of embeddings](https://drive.google.com/open?id=1vlUxYlCAp_U0QmWgYizn8SRgxEpPsDDm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5y95RZhFwmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) #make sure you do this!\n",
        "# define the loss function:\n",
        "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
        "# define the training step:\n",
        "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
        "n_iters = 10000\n",
        "# train for n_iter iterations\n",
        "for _ in range(n_iters):\n",
        "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
        "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvAnCsXuF4Za",
        "colab_type": "code",
        "outputId": "17ce9d7e-2794-453b-acfa-5b346c174723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(sess.run(W1))\n",
        "print('----------')\n",
        "print(sess.run(b1))\n",
        "print('----------')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.11995198  0.05235916 -0.00252951  1.7535975   0.4686913 ]\n",
            " [-1.4756694   0.17503612 -1.76187    -0.4813566  -0.6249435 ]\n",
            " [-1.7231231  -0.30293754  0.59900236  0.39750138  0.01570713]\n",
            " [ 0.92398554 -2.0858347   0.5572174   0.27773723  0.08335201]\n",
            " [ 1.4416847   0.5458765   0.61699885 -1.7098467  -1.4785556 ]\n",
            " [ 0.8200696   0.721835   -0.54296786 -1.1632943   2.1976342 ]\n",
            " [-1.4835261   0.6136435   0.70306635  1.4862514  -0.3040603 ]]\n",
            "----------\n",
            "[-1.1953249  -1.0833192   0.81202847  0.24949035 -0.01329913]\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HroLHZwYF9kJ",
        "colab_type": "code",
        "outputId": "1510c4bc-78c7-4d98-ee48-7cb7e9afb161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "vectors = sess.run(W1 + b1)\n",
        "\n",
        "# if you work it out, you will see that it has the same effect as running the node hidden representation\n",
        "print(vectors)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.0753729e+00 -1.0309601e+00  8.0949897e-01  2.0030878e+00\n",
            "   4.5539215e-01]\n",
            " [-2.6709943e+00 -9.0828305e-01 -9.4984156e-01 -2.3186624e-01\n",
            "  -6.3824260e-01]\n",
            " [-2.9184480e+00 -1.3862567e+00  1.4110308e+00  6.4699173e-01\n",
            "   2.4079951e-03]\n",
            " [-2.7133936e-01 -3.1691539e+00  1.3692459e+00  5.2722758e-01\n",
            "   7.0052877e-02]\n",
            " [ 2.4635983e-01 -5.3744268e-01  1.4290273e+00 -1.4603564e+00\n",
            "  -1.4918547e+00]\n",
            " [-3.7525529e-01 -3.6148417e-01  2.6906061e-01 -9.1380394e-01\n",
            "   2.1843350e+00]\n",
            " [-2.6788511e+00 -4.6967566e-01  1.5150948e+00  1.7357417e+00\n",
            "  -3.1735945e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qiggqq_HGJYE",
        "colab_type": "code",
        "outputId": "39c8c50f-2863-4b47-a2e8-89fce31ec126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(vectors[ word2int['queen'] ])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.27133936 -3.169154    1.3692459   0.5272276   0.07005288]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngxIiyHVGS4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_dist(vec1, vec2):\n",
        "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
        "def find_closest(word_index, vectors):\n",
        "    min_dist = 10000 # to act like positive infinity\n",
        "    min_index = -1\n",
        "    query_vector = vectors[word_index]\n",
        "    for index, vector in enumerate(vectors):\n",
        "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
        "            min_dist = euclidean_dist(vector, query_vector)\n",
        "            min_index = index\n",
        "    return min_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxP3cJgUGVpG",
        "colab_type": "code",
        "outputId": "2d93d97d-938a-43cb-ee28-2d3f1a6a174c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(int2word[find_closest(word2int['queen'], vectors)])\n",
        "print(int2word[find_closest(word2int['he'], vectors)])\n",
        "print(int2word[find_closest(word2int['she'], vectors)])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king\n",
            "she\n",
            "he\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2TgIk5HGXkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "model = TSNE(n_components=2, random_state=0)\n",
        "np.set_printoptions(suppress=True)\n",
        "vectors = model.fit_transform(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGELC7k-Gg31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "normalizer = preprocessing.Normalizer()\n",
        "vectors =  normalizer.fit_transform(vectors, 'l2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw5FILeAGi6D",
        "colab_type": "code",
        "outputId": "ff3e348b-8f38-44cc-9cfb-8be72132e1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "for word in words:\n",
        "    print(word, vectors[word2int[word]][1])\n",
        "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king -0.96309465\n",
            "royal -0.86308813\n",
            "he -0.4225477\n",
            "queen -0.9945276\n",
            "is 0.83077204\n",
            "the 0.6369875\n",
            "she -0.17015862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq8AAAHGCAYAAABacmKSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFEVJREFUeJzt3WGo5fV95/HPN1rTkNoIcTaIo1Wy\nk1i1xSQXN4sPDCTZqAR90GxRErppJPOkmmYbBIslLfZJWtluKGhblw3ZFpqs9UEZqMVCVwmIBmcw\nK2qwTKyNYwVtGiUhJDrZ7z64N5mbyczcq3bOme+c1wsGzv+c3zl8+XFneM///s851d0BAIAJ3rDs\nAQAAYLvEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFVkJVfaGqnq+qx47yeFXVH1fV/qp6tKre\nvegZAdiaeAVWxReTXHGMx69Msmvjz+4kf7KAmQB4lcQrsBK6+ytJ/vUYS65J8ue97qEkZ1TVWYuZ\nDoDtEq8A685O8sym4wMb9wFwAjl12QMATFNVu7N+aUHe/OY3v+eCCy5Y8kQAs+zbt+9funvHa3mu\neAVY92ySczYd79y476d0951J7kyStbW13rt37/GfDuAkUlX/9Fqf67IBgHV7kvzaxqcOvDfJS939\n3LKHAuAnOfMKrISq+lKS9yU5s6oOJPndJD+TJN39p0nuSXJVkv1Jvpfk15czKQDHIl6BldDd123x\neCf5jQWNA8Br5LIBAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQrAABjiFcAAMYQ\nrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIAMIZ4\nBQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQr\nAABjiFcAAMYQrwAAjCFeAQAYQ7wCK6OqrqiqJ6tqf1XdfITHz62q+6rqkap6tKquWsacABydeAVW\nQlWdkuT2JFcmuTDJdVV14WHLfifJXd39riTXJrljsVMCsBXxCqyKS5Ps7+6nuvvlJF9Ocs1hazrJ\nz2/cfkuSf17gfABsw6nLHgBgQc5O8sym4wNJ/sNha34vyd9V1Y1J3pzkA4sZDYDtcuYV4JDrknyx\nu3cmuSrJX1TVT/07WVW7q2pvVe194YUXFj4kwCoTr8CqeDbJOZuOd27ct9n1Se5Kku5+MMnPJjnz\n8Bfq7ju7e62713bs2HGcxgXgSMQrsCoeTrKrqs6vqtOy/oasPYet+WaS9ydJVf1i1uPVqVWAE4h4\nBVZCdx9MckOSe5N8PeufKvB4Vd1aVVdvLPtMkk9W1f9N8qUkH+/uXs7EAByJN2wBK6O770lyz2H3\nfXbT7SeSXLbouQDYPmdeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4B\nABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoA\nwBjiFQCAMcQrAABjiFcAgNfhxRdfzB133JEkuf/++/PhD394yROd3MQrAMDrsDleOf7EKwDA63Dz\nzTfnG9/4Ri655JLcdNNN+e53v5uPfOQjueCCC/LRj3403Z0k2bdvXy6//PK85z3vyYc+9KE899xz\nS558JvEKAPA6fO5zn8vb3/72fO1rX8ttt92WRx55JJ///OfzxBNP5KmnnsoDDzyQV155JTfeeGPu\nvvvu7Nu3L5/4xCdyyy23LHv0kU5d9gAAACeTSy+9NDt37kySXHLJJXn66adzxhln5LHHHssHP/jB\nJMkPf/jDnHXWWcsccyzxCgDwb+iNb3zjj2+fcsopOXjwYLo7F110UR588MElTnZycNkAAMDrcPrp\np+c73/nOMde8853vzAsvvPDjeH3llVfy+OOPL2K8k44zrwAAr8Nb3/rWXHbZZbn44ovzpje9KW97\n29t+as1pp52Wu+++O5/61Kfy0ksv5eDBg/n0pz+diy66aAkTz1Y/egccAK/e2tpa7927d9ljAIxS\nVfu6e+21PNdlAwAAjCFeAQAYQ7wCADCGeAVWRlVdUVVPVtX+qrr5KGt+taqeqKrHq+ovFz0jAMfm\n0waAlVBVpyS5PckHkxxI8nBV7enuJzat2ZXkt5Nc1t3frqp/t5xpATgaZ16BVXFpkv3d/VR3v5zk\ny0muOWzNJ5Pc3t3fTpLufn7BMwKwBfEKrIqzkzyz6fjAxn2bvSPJO6rqgap6qKquWNh0AGyLywYA\nDjk1ya4k70uyM8lXquqXuvvFzYuqaneS3Uly7rnnLnpGgJXmzCuwKp5Ncs6m450b9212IMme7n6l\nu/8xyT9kPWZ/Qnff2d1r3b22Y8eO4zYwAD9NvAKr4uEku6rq/Ko6Lcm1SfYctuavs37WNVV1ZtYv\nI3hqkUMCcGziFVgJ3X0wyQ1J7k3y9SR3dffjVXVrVV29sezeJN+qqieS3Jfkpu7+1nImBuBIqruX\nPQPAWGtra713795ljwEwSlXt6+611/JcZ14BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hX\nAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wC\nADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUA\ngDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QqsjKq6oqqerKr9VXXzMdb9SlV1Va0t\ncj4AtiZegZVQVackuT3JlUkuTHJdVV14hHWnJ/nNJF9d7IQAbId4BVbFpUn2d/dT3f1yki8nueYI\n634/yR8k+f4ihwNge8QrsCrOTvLMpuMDG/f9WFW9O8k53f03ixwMgO0TrwBJquoNSf4oyWe2sXZ3\nVe2tqr0vvPDC8R8OgB8Tr8CqeDbJOZuOd27c9yOnJ7k4yf1V9XSS9ybZc6Q3bXX3nd291t1rO3bs\nOI4jA3A48QqsioeT7Kqq86vqtCTXJtnzowe7+6XuPrO7z+vu85I8lOTq7t67nHEBOBLxCqyE7j6Y\n5IYk9yb5epK7uvvxqrq1qq5e7nQAbNepyx4AYFG6+54k9xx232ePsvZ9i5gJgFfHmVcAAMYQrwAA\njCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBg\nDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQrAABj\niFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV6BlVFV\nV1TVk1W1v6puPsLjv1VVT1TVo1X191X1C8uYE4CjE6/ASqiqU5LcnuTKJBcmua6qLjxs2SNJ1rr7\nl5PcneQPFzslAFsRr8CquDTJ/u5+qrtfTvLlJNdsXtDd93X39zYOH0qyc8EzArAF8QqsirOTPLPp\n+MDGfUdzfZK/Pa4TAfCqnbrsAQBONFX1sSRrSS4/yuO7k+xOknPPPXeBkwHgzCuwKp5Ncs6m450b\n9/2EqvpAkluSXN3dPzjSC3X3nd291t1rO3bsOC7DAnBk4hVYFQ8n2VVV51fVaUmuTbJn84KqeleS\nP8t6uD6/hBkB2IJ4BVZCdx9MckOSe5N8Pcld3f14Vd1aVVdvLLstyc8l+auq+lpV7TnKywGwJK55\nBVZGd9+T5J7D7vvsptsfWPhQALwqzrwCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACM\nIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM\n8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOI\nVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hVYGVV1RVU9WVX7q+rmIzz+xqr63xuPf7Wq\nzlv8lAAci3gFVkJVnZLk9iRXJrkwyXVVdeFhy65P8u3u/vdJ/nuSP1jslABsRbwCq+LSJPu7+6nu\nfjnJl5Ncc9iaa5L8r43bdyd5f1XVAmcEYAviFVgVZyd5ZtPxgY37jrimuw8meSnJWxcyHQDbcuqy\nBwCYpqp2J9m9cfiDqnpsmfOcQM5M8i/LHuIEYS8OsReH2ItD3vlanyhegVXxbJJzNh3v3LjvSGsO\nVNWpSd6S5FuHv1B335nkziSpqr3dvXZcJh7GXhxiLw6xF4fYi0Oqau9rfa7LBoBV8XCSXVV1flWd\nluTaJHsOW7MnyX/ZuP2RJP+nu3uBMwKwBWdegZXQ3Qer6oYk9yY5JckXuvvxqro1yd7u3pPkfyb5\ni6ran+Rfsx64AJxAxCuwMrr7niT3HHbfZzfd/n6S//wqX/bOf4PRThb24hB7cYi9OMReHPKa96L8\nRgwAgClc8woAwBjiFWAbfLXsIdvYi9+qqieq6tGq+vuq+oVlzLkIW+3FpnW/UlVdVSftO823sxdV\n9asbPxuPV9VfLnrGRdnG35Fzq+q+qnpk4+/JVcuY83irqi9U1fNH+zjBWvfHG/v0aFW9ezuvK14B\ntuCrZQ/Z5l48kmStu385699U9oeLnXIxtrkXqarTk/xmkq8udsLF2c5eVNWuJL+d5LLuvijJpxc+\n6AJs8+fid5Lc1d3vyvobQ+9Y7JQL88UkVxzj8SuT7Nr4szvJn2znRcUrwNZ8tewhW+5Fd9/X3d/b\nOHwo65+pezLazs9Fkvx+1v8z8/1FDrdg29mLTya5vbu/nSTd/fyCZ1yU7exFJ/n5jdtvSfLPC5xv\nYbr7K1n/5JajuSbJn/e6h5KcUVVnbfW64hVga75a9pDt7MVm1yf52+M60fJsuRcbvwY9p7v/ZpGD\nLcF2fi7ekeQdVfVAVT1UVcc6IzfZdvbi95J8rKoOZP0TUG5czGgnnFf770kSH5UFwHFSVR9Lspbk\n8mXPsgxV9YYkf5Tk40se5URxatZ/Pfy+rJ+N/0pV/VJ3v7jUqZbjuiRf7O7/VlX/MeufL31xd/+/\nZQ82gTOvAFt7NV8tm2N9texJYDt7kar6QJJbklzd3T9Y0GyLttVenJ7k4iT3V9XTSd6bZM9J+qat\n7fxcHEiyp7tf6e5/TPIPWY/Zk8129uL6JHclSXc/mORnk5y5kOlOLNv69+Rw4hVga75a9pAt96Kq\n3pXkz7IerifrdY3JFnvR3S9195ndfV53n5f163+v7u7X/J3uJ7Dt/B3566yfdU1VnZn1ywieWuSQ\nC7KdvfhmkvcnSVX9Ytbj9YWFTnli2JPk1zY+deC9SV7q7ue2epLLBgC24KtlD9nmXtyW5OeS/NXG\ne9a+2d1XL23o42Sbe7EStrkX9yb5T1X1RJIfJrmpu0+6305scy8+k+R/VNV/zfqbtz5+Mv5nt6q+\nlPX/sJy5cX3v7yb5mSTp7j/N+vW+VyXZn+R7SX59W697Eu4VAAAnKZcNAAAwhngFAGAM8QoAwBji\nFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCv\nAACMIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngF\nAGAM8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsA\nAGOIVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEA\nGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDA\nGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADG\nEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCG\neAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHE\nKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFe\nAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBgDPEK\nAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCAMcQrAABjiFcA\nAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIA\nMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM8QoAwBjiFQCA\nMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOIVwAAxhCvAACM\nIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8AgAwhngFAGAM\n8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIVAIAxxCsAAGOI\nVwAAxhCvAACMIV4BABhDvAIAMIZ4BQBgDPEKAMAY4hUAgDHEKwAAY4hXAADGEK8AAIwhXgEAGEO8\nAgAwhngFAGAM8QoAwBjiFQCAMcQrAABjiFcAAMYQrwAAjCFeAQAYQ7wCADCGeAUAYAzxCgDAGOIV\nAIAxxCsAAGOIVwAAxhCvAACMIV4BABhDvAIAMMb/B5R9JZFaI7quAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7BwPZQbGkoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}